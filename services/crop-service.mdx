---
title: Crop Service
description: "Intelligently detect and crop product images from screenshots using Gemini 2.0 Flash bounding box detection."
---

The Crop Service uses AI vision to detect the main product in a screenshot and crop it, removing UI elements, logos, and other distractions. It uses Gemini 2.0 Flash with native bounding box detection.

**File**: `app/services/image_crop_service.py`

## Function

<ParamField body="crop_product_image" type="async function">
  Detects product bounding box and crops the image to focus on the product.
</ParamField>

```python title="function_signature.py"
async def crop_product_image(
    base64_image: str,
    ocr_context: Optional[Dict[str, Any]] = None,
    padding_percent: float = 0.20
) -> str
```

<ParamField body="base64_image" type="string" required>
  Base64-encoded full screenshot
</ParamField>
<ParamField body="ocr_context" type="dict" optional>
  OCR data (name, category, object_type) to help locate product
</ParamField>
<ParamField body="padding_percent" type="float" optional>
  Padding around detected bbox (default: 20%)
</ParamField>

**Returns**: Base64-encoded cropped image (or original if detection fails)

## How It Works

1. **Bounding Box Detection**: Gemini 2.0 Flash analyzes the image and returns normalized coordinates (0-1000) for the product location.

2. **Coordinate Conversion**: Normalized coordinates are converted to pixel coordinates based on image dimensions.

3. **Validation**: Bounding box is validated to ensure it's within image bounds and has valid dimensions.

4. **Cropping with Padding**: Image is cropped to the detected area with configurable padding (default 20%).

5. **Fallback**: If detection fails, returns the original image unchanged.

## Implementation

### Bounding Box Detection

```python title="bbox_detection.py"
async def _detect_product_bbox(
    base64_image: str, 
    ocr_context: Optional[Dict[str, Any]] = None
) -> Optional[Tuple[int, int, int, int]]:
    # Load image to get dimensions
    image_bytes = base64.b64decode(base64_image)
    image = Image.open(io.BytesIO(image_bytes))
    img_width, img_height = image.size

    # Use Gemini 2.0 Flash with native bbox support
    model = genai.GenerativeModel("gemini-2.5-flash")
    
    # Build prompt with OCR context
    object_type = "product"
    if ocr_context:
        object_type = ocr_context.get("object_type", "product")
    
    prompt = f"""Locate the {object_type} in this image.
    Return ONLY a bounding box as JSON array: [ymin, xmin, ymax, xmax]
    Coordinates are normalized 0-1000."""
    
    # Get bounding box (normalized 0-1000)
    response = model.generate_content(
        [prompt, image_part],
        generation_config={
            "response_mime_type": "application/json",
            "temperature": 0
        }
    )
    
    # Convert normalized to pixels
    ymin, xmin, ymax, xmax = json.loads(response.text)
    x = int(xmin * img_width / 1000)
    y = int(ymin * img_height / 1000)
    width = int((xmax - xmin) * img_width / 1000)
    height = int((ymax - ymin) * img_height / 1000)
    
    return (x, y, width, height)
```

### Cropping with Padding

```python title="crop_with_padding.py"
async def _crop_with_bbox(
    base64_image: str, 
    bbox: Tuple[int, int, int, int], 
    padding_percent: float = 0.20
) -> str:
    image_bytes = base64.b64decode(base64_image)
    image = Image.open(io.BytesIO(image_bytes))
    
    x, y, width, height = bbox
    
    # Add padding
    pad_w = int(width * padding_percent)
    pad_h = int(height * padding_percent)
    
    x1 = max(0, x - pad_w)
    y1 = max(0, y - pad_h)
    x2 = min(img_width, x + width + pad_w)
    y2 = min(img_height, y + height + pad_h)
    
    # Crop and encode
    cropped_image = image.crop((x1, y1, x2, y2))
    output = io.BytesIO()
    cropped_image.save(output, format="JPEG", quality=95)
    
    return base64.b64encode(output.getvalue()).decode("utf-8")
```

## Usage Example

```python title="usage_example.py"
from app.services.image_crop_service import crop_product_image

# With OCR context (recommended)
cropped_image = await crop_product_image(
    base64_image=base64_image,
    ocr_context={
        "name": "Leather Jacket",
        "object_type": "jacket",
        "category": "Fashion"
    },
    padding_percent=0.20
)

# Without OCR context
cropped_image = await crop_product_image(base64_image)
```

## OCR Context Benefits

Using OCR context helps the model:

- **Focus on Product**: Avoids cropping logos or UI elements
- **Better Accuracy**: Uses product name/type as hints

Example: If OCR detects "sunglasses", the model will look for sunglasses instead of random objects.

## Performance

| Metric | Value |
|--------|-------|
| Average Time | 2-3 seconds per image |
| Success Rate | 90%+ (falls back gracefully) |
| Model | Gemini 2.5 Flash |
| Padding | Default 20% (configurable) |

## Configuration

Add to your `.env` file:

```bash title=".env"
OBJDETECT_API_KEY=your_gemini_api_key_here
```

Get your API key from: [Google AI Studio](https://makersuite.google.com/app/apikey)

## Dependencies

```txt title="requirements.txt"
google-generativeai>=0.3.0
pillow>=10.0.0
```

Install with:
```bash
pip install google-generativeai pillow
```

## Error Handling

The service implements graceful degradation:

- If detection fails → returns original image
- If bbox is invalid → returns original image
- If cropping fails → returns original image

The pipeline continues even if cropping fails.

## Coordinate System

Gemini returns normalized coordinates (0-1000):
- `[0, 0]` = top-left corner
- `[1000, 1000]` = bottom-right corner

These are converted to pixel coordinates based on actual image dimensions.

## Limitations

| Limitation | Description |
|------------|-------------|
| Multiple Products | Currently detects only the main/primary product. Multiple products may confuse the model |
| Complex Backgrounds | Very cluttered backgrounds may reduce detection accuracy |
| Small Products | Very small products in large screenshots may be missed |

<Note>
  V2 will use a custom trained model for bounding box detection, improving accuracy and speed.
</Note>

## Related Resources

- [Search Enrichment](/services/search-enrichment) - Uses cropped images
- [Architecture](/architecture) - See how services connect
